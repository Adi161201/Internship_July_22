{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"gpuClass":"standard","accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbkLsXZ5dlyM","outputId":"b948bae7-e514-4402-84de-f2e491806c79","execution":{"iopub.status.busy":"2023-04-23T09:39:17.120797Z","iopub.execute_input":"2023-04-23T09:39:17.121186Z","iopub.status.idle":"2023-04-23T09:39:17.187543Z","shell.execute_reply.started":"2023-04-23T09:39:17.121152Z","shell.execute_reply":"2023-04-23T09:39:17.186470Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lx3_TOC--lrr","outputId":"bed1f408-759e-474b-9ad1-30878f426b4a","execution":{"iopub.status.busy":"2023-04-23T09:39:17.189649Z","iopub.execute_input":"2023-04-23T09:39:17.190249Z","iopub.status.idle":"2023-04-23T09:39:29.813376Z","shell.execute_reply.started":"2023-04-23T09:39:17.190210Z","shell.execute_reply":"2023-04-23T09:39:29.812169Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.27.4)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.13.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.11.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader,SubsetRandomSampler\nimport torch.optim as optim\n\nimport os\nimport copy\nfrom collections import defaultdict\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nfrom pylab import rcParams\nimport csv\nimport time\nfrom tqdm import tqdm\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n\nfrom transformers import AutoTokenizer,AutoModel,AutoModelForSequenceClassification,AdamW,get_linear_schedule_with_warmup ,AutoConfig , BertTokenizer, BertForSequenceClassification\n\nseed_val = 42 \nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)","metadata":{"id":"6O2leCTQeIza","execution":{"iopub.status.busy":"2023-04-23T09:39:29.815531Z","iopub.execute_input":"2023-04-23T09:39:29.815926Z","iopub.status.idle":"2023-04-23T09:39:51.568645Z","shell.execute_reply.started":"2023-04-23T09:39:29.815892Z","shell.execute_reply":"2023-04-23T09:39:51.567385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device('cuda')\n    print(\"Running on gpu\",torch.cuda.get_device_name(0))\nelse:\n    device = 'cpu'\n    print('No GPU found Running on cpu')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BbTb7HTAO-Bd","outputId":"2a10abe4-5508-47c8-c3c6-f6e3075cfc1b","execution":{"iopub.status.busy":"2023-04-23T09:39:51.571905Z","iopub.execute_input":"2023-04-23T09:39:51.572212Z","iopub.status.idle":"2023-04-23T09:39:51.711909Z","shell.execute_reply.started":"2023-04-23T09:39:51.572179Z","shell.execute_reply":"2023-04-23T09:39:51.710390Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Running on gpu Tesla T4\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/amazon-product-length-prediction-dataset/dataset/train.csv')\ntest_df = pd.read_csv('/kaggle/input/amazon-product-length-prediction-dataset/dataset/test.csv')\nsample_df = pd.read_csv('/kaggle/input/amazon-product-length-prediction-dataset/dataset/sample_submission.csv')","metadata":{"id":"h6wd4lLiPom2","execution":{"iopub.status.busy":"2023-04-23T09:39:51.715053Z","iopub.execute_input":"2023-04-23T09:39:51.716130Z","iopub.status.idle":"2023-04-23T09:41:00.304243Z","shell.execute_reply.started":"2023-04-23T09:39:51.716085Z","shell.execute_reply":"2023-04-23T09:41:00.303021Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_df['TITLE'].isnull().sum()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cfo0KVKHQU4I","outputId":"6ef646d1-6ed0-47c5-c5a0-03b46f44a6d2","execution":{"iopub.status.busy":"2023-04-23T09:41:00.305909Z","iopub.execute_input":"2023-04-23T09:41:00.306342Z","iopub.status.idle":"2023-04-23T09:41:00.422295Z","shell.execute_reply.started":"2023-04-23T09:41:00.306303Z","shell.execute_reply":"2023-04-23T09:41:00.421174Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"12"},"metadata":{}}]},{"cell_type":"code","source":"len(train_df)-len(train_df.drop_duplicates())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8r8zXbZwQm1s","outputId":"89609b29-8e1d-4a25-e927-ee63bc26ad4f","execution":{"iopub.status.busy":"2023-04-23T09:41:00.423788Z","iopub.execute_input":"2023-04-23T09:41:00.424240Z","iopub.status.idle":"2023-04-23T09:41:05.641544Z","shell.execute_reply.started":"2023-04-23T09:41:00.424201Z","shell.execute_reply":"2023-04-23T09:41:05.640338Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"NO duplicates present","metadata":{"id":"m9gj-ZQCQ6u2"}},{"cell_type":"code","source":"train_df = train_df[train_df['TITLE'].notnull()]","metadata":{"id":"zt6-M3BLQr8S","execution":{"iopub.status.busy":"2023-04-23T09:41:05.643209Z","iopub.execute_input":"2023-04-23T09:41:05.643729Z","iopub.status.idle":"2023-04-23T09:41:06.036248Z","shell.execute_reply.started":"2023-04-23T09:41:05.643670Z","shell.execute_reply":"2023-04-23T09:41:06.034872Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"eMFc-yyxRcIt","outputId":"6e911387-8027-441a-ff1a-86903017d3d4","execution":{"iopub.status.busy":"2023-04-23T09:41:06.037913Z","iopub.execute_input":"2023-04-23T09:41:06.038775Z","iopub.status.idle":"2023-04-23T09:41:06.058984Z","shell.execute_reply.started":"2023-04-23T09:41:06.038734Z","shell.execute_reply":"2023-04-23T09:41:06.057763Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   PRODUCT_ID                                              TITLE  \\\n0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n4      283658  The United Empire Loyalists: A Chronicle of th...   \n\n                                       BULLET_POINTS  \\\n0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n3  [Made By 95%cotton and 5% Lycra which gives yo...   \n4                                                NaN   \n\n                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n0                                                NaN             1650   \n1                                                NaN             2755   \n2  Specifications: Color: Red, Material: Aluminiu...             7537   \n3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n4                                                NaN             6112   \n\n   PRODUCT_LENGTH  \n0     2125.980000  \n1      393.700000  \n2      748.031495  \n3      787.401574  \n4      598.424000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>BULLET_POINTS</th>\n      <th>DESCRIPTION</th>\n      <th>PRODUCT_TYPE_ID</th>\n      <th>PRODUCT_LENGTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1925202</td>\n      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n      <td>NaN</td>\n      <td>1650</td>\n      <td>2125.980000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2673191</td>\n      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n      <td>NaN</td>\n      <td>2755</td>\n      <td>393.700000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2765088</td>\n      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n      <td>7537</td>\n      <td>748.031495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1594019</td>\n      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n      <td>2996</td>\n      <td>787.401574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>283658</td>\n      <td>The United Empire Loyalists: A Chronicle of th...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6112</td>\n      <td>598.424000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df= train_df.sample(100000)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T09:41:06.063503Z","iopub.execute_input":"2023-04-23T09:41:06.063852Z","iopub.status.idle":"2023-04-23T09:41:06.169658Z","shell.execute_reply.started":"2023-04-23T09:41:06.063822Z","shell.execute_reply":"2023-04-23T09:41:06.168417Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-23T09:41:06.171114Z","iopub.execute_input":"2023-04-23T09:41:06.172139Z","iopub.status.idle":"2023-04-23T09:41:06.180744Z","shell.execute_reply.started":"2023-04-23T09:41:06.172096Z","shell.execute_reply":"2023-04-23T09:41:06.179542Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(100000, 6)"},"metadata":{}}]},{"cell_type":"code","source":"sentences = train_df['TITLE'].values \nlabels = train_df['PRODUCT_LENGTH'].values","metadata":{"id":"q5pejAUYRhBd","execution":{"iopub.status.busy":"2023-04-23T09:41:06.182181Z","iopub.execute_input":"2023-04-23T09:41:06.182617Z","iopub.status.idle":"2023-04-23T09:41:06.191306Z","shell.execute_reply.started":"2023-04-23T09:41:06.182568Z","shell.execute_reply":"2023-04-23T09:41:06.190367Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmNbN7w0mtdZ","outputId":"a1933e27-37dc-4f91-a8d7-dae9153d90cc","execution":{"iopub.status.busy":"2023-04-23T09:41:06.192921Z","iopub.execute_input":"2023-04-23T09:41:06.193476Z","iopub.status.idle":"2023-04-23T09:41:06.203251Z","shell.execute_reply.started":"2023-04-23T09:41:06.193430Z","shell.execute_reply":"2023-04-23T09:41:06.201765Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([ 433.07      ,  838.58267631,   19.685     , ..., 1181.102361  ,\n        800.        , 1141.7322823 ])"},"metadata":{}}]},{"cell_type":"code","source":"print(sentences.shape,labels.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RRfMScymRvY4","outputId":"856c24a5-b9db-462c-912a-e10edea51fee","execution":{"iopub.status.busy":"2023-04-23T09:41:06.205044Z","iopub.execute_input":"2023-04-23T09:41:06.205604Z","iopub.status.idle":"2023-04-23T09:41:06.214578Z","shell.execute_reply.started":"2023-04-23T09:41:06.205563Z","shell.execute_reply":"2023-04-23T09:41:06.213258Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(100000,) (100000,)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_sentences, val_sentences,train_labels,val_labels = train_test_split(sentences,labels,test_size = 0.2,random_state=seed_val)","metadata":{"id":"KQeNuAiJRyWU","execution":{"iopub.status.busy":"2023-04-23T09:41:06.216415Z","iopub.execute_input":"2023-04-23T09:41:06.218016Z","iopub.status.idle":"2023-04-23T09:41:06.234357Z","shell.execute_reply.started":"2023-04-23T09:41:06.217914Z","shell.execute_reply":"2023-04-23T09:41:06.233307Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(f\"No. of training sentences {len(train_sentences)}\")\nprint(f\"No. of validation sentences {len(val_sentences)}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYxuSs2-R6jU","outputId":"d4e11e27-accb-46f2-cb23-1126c47fb88c","execution":{"iopub.status.busy":"2023-04-23T09:41:06.235793Z","iopub.execute_input":"2023-04-23T09:41:06.236225Z","iopub.status.idle":"2023-04-23T09:41:06.245937Z","shell.execute_reply.started":"2023-04-23T09:41:06.236172Z","shell.execute_reply":"2023-04-23T09:41:06.244681Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"No. of training sentences 80000\nNo. of validation sentences 20000\n","output_type":"stream"}]},{"cell_type":"code","source":"model_name = 'bert-base-uncased'\nmax_input_length = 128\nbatch_size = 64","metadata":{"id":"thFIhYErSEtx","execution":{"iopub.status.busy":"2023-04-23T09:41:06.247847Z","iopub.execute_input":"2023-04-23T09:41:06.248295Z","iopub.status.idle":"2023-04-23T09:41:06.256067Z","shell.execute_reply.started":"2023-04-23T09:41:06.248220Z","shell.execute_reply":"2023-04-23T09:41:06.255243Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"LwC8UMG3TvzZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n# model = BertRegressor.from_pretrained('bert-base-uncased')","metadata":{"id":"ZLN8vHCETyB7","execution":{"iopub.status.busy":"2023-04-23T09:41:06.257434Z","iopub.execute_input":"2023-04-23T09:41:06.258491Z","iopub.status.idle":"2023-04-23T09:41:07.428928Z","shell.execute_reply.started":"2023-04-23T09:41:06.258457Z","shell.execute_reply":"2023-04-23T09:41:07.427875Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e13a6e06b35b4a0fa8126f377ccdd3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3a48cb9962f49f9ac93f2492651db1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76bd718e70e846b39f70c7289154443f"}},"metadata":{}}]},{"cell_type":"code","source":"idx = 10000\nsample_text = sentences[idx]\ntokens =tokenizer.tokenize(sample_text)\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\nprint('Sample text {}'.format(sample_text))\nprint('Tokens {}'.format(tokens))\nprint('Token IDS {}'.format(token_ids))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lh9Y-INxT26Y","outputId":"2edb9503-6e85-44d1-9900-5ddd6c7bd614","execution":{"iopub.status.busy":"2023-04-23T09:41:39.564721Z","iopub.execute_input":"2023-04-23T09:41:39.565434Z","iopub.status.idle":"2023-04-23T09:41:39.573484Z","shell.execute_reply.started":"2023-04-23T09:41:39.565398Z","shell.execute_reply":"2023-04-23T09:41:39.572205Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Sample text Dream Homme 200 GSM Microfibre Reversible Comforter Double Bed (Glowing Grey & Pretty Peach) 1 Piece\nTokens ['dream', 'homme', '200', 'gs', '##m', 'micro', '##fi', '##bre', 'rev', '##ers', '##ible', 'comfort', '##er', 'double', 'bed', '(', 'glowing', 'grey', '&', 'pretty', 'peach', ')', '1', 'piece']\nToken IDS [3959, 26574, 3263, 28177, 2213, 12702, 8873, 13578, 7065, 2545, 7028, 7216, 2121, 3313, 2793, 1006, 10156, 4462, 1004, 3492, 18237, 1007, 1015, 3538]\n","output_type":"stream"}]},{"cell_type":"code","source":"encoding = tokenizer.encode_plus(\n    sample_text,\n    max_length = max_input_length,\n    add_special_tokens = True,\n    pad_to_max_length=True,\n    return_attention_mask = True,\n    return_token_type_ids = False,\n    return_tensors = 'pt'\n)\n\ninput_ids = encoding['input_ids']\nattention_mask = encoding['attention_mask']\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpeoEPtiT94M","outputId":"a3834d0d-4fcf-4072-9cc3-63cb857ec916","execution":{"iopub.status.busy":"2023-04-23T09:41:39.575580Z","iopub.execute_input":"2023-04-23T09:41:39.576092Z","iopub.status.idle":"2023-04-23T09:41:39.626715Z","shell.execute_reply.started":"2023-04-23T09:41:39.576050Z","shell.execute_reply":"2023-04-23T09:41:39.625635Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2352: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"encoding","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r21DVcmPUcun","outputId":"c671f099-287e-4cc3-a183-9f51ed702427","execution":{"iopub.status.busy":"2023-04-23T09:41:39.628717Z","iopub.execute_input":"2023-04-23T09:41:39.629418Z","iopub.status.idle":"2023-04-23T09:41:39.682716Z","shell.execute_reply.started":"2023-04-23T09:41:39.629381Z","shell.execute_reply":"2023-04-23T09:41:39.681586Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[  101,  3959, 26574,  3263, 28177,  2213, 12702,  8873, 13578,  7065,\n          2545,  7028,  7216,  2121,  3313,  2793,  1006, 10156,  4462,  1004,\n          3492, 18237,  1007,  1015,  3538,   102,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]])}"},"metadata":{}}]},{"cell_type":"code","source":"encoding.keys()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DKkq6UqmUfFq","outputId":"38273e5d-3082-402c-f80f-d2e680d5892b","execution":{"iopub.status.busy":"2023-04-23T09:41:39.684249Z","iopub.execute_input":"2023-04-23T09:41:39.684945Z","iopub.status.idle":"2023-04-23T09:41:39.692000Z","shell.execute_reply.started":"2023-04-23T09:41:39.684906Z","shell.execute_reply":"2023-04-23T09:41:39.690730Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"# Load the pre-trained BERT model configuration with 768 hidden units\nconfig = AutoConfig.from_pretrained(model_name, hidden_size=768)\n\n# Load the pre-trained BERT model\nbase_model = AutoModel.from_pretrained('bert-base-uncased', config=config)\n\n# Freeze the parameters of the pre-trained BERT model\nfor param in base_model.parameters():\n    param.requires_grad = False\n\n# Add a new output layer for regression\nbase_model.pooler = nn.Linear(config.hidden_size, 1)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RkVIJLe2Ul-Y","outputId":"72193d59-c967-4663-a055-88dc624cca85","execution":{"iopub.status.busy":"2023-04-23T09:41:39.695130Z","iopub.execute_input":"2023-04-23T09:41:39.696012Z","iopub.status.idle":"2023-04-23T09:41:45.106734Z","shell.execute_reply.started":"2023-04-23T09:41:39.695971Z","shell.execute_reply":"2023-04-23T09:41:45.105408Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33b178d2b98245a59b8f52da6185a7de"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model(**encoding)['pooler_output']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5xtMkoPVBn0F","outputId":"7bd54f05-636b-43ac-d8ac-e4eba0a5389a","execution":{"iopub.status.busy":"2023-04-23T09:41:45.108350Z","iopub.execute_input":"2023-04-23T09:41:45.109968Z","iopub.status.idle":"2023-04-23T09:41:45.653398Z","shell.execute_reply.started":"2023-04-23T09:41:45.109926Z","shell.execute_reply":"2023-04-23T09:41:45.652215Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 1.7150e-01],\n         [-2.3769e-01],\n         [ 2.2204e-01],\n         [-1.5723e-02],\n         [ 2.9161e-01],\n         [ 4.5334e-01],\n         [ 4.0109e-01],\n         [ 3.8685e-01],\n         [ 3.1239e-01],\n         [ 3.1975e-01],\n         [ 5.2331e-01],\n         [ 4.8750e-01],\n         [ 3.7797e-01],\n         [ 5.8159e-01],\n         [ 2.8641e-01],\n         [ 2.4587e-01],\n         [ 4.6253e-01],\n         [-8.1294e-02],\n         [-2.3663e-01],\n         [ 6.7542e-02],\n         [ 2.1351e-01],\n         [ 1.4472e-01],\n         [-4.2979e-02],\n         [-1.6302e-01],\n         [ 5.2513e-01],\n         [ 5.5770e-04],\n         [-8.7731e-03],\n         [-5.5674e-02],\n         [ 3.7276e-02],\n         [-9.3443e-02],\n         [ 7.5440e-02],\n         [-2.7459e-02],\n         [ 2.4697e-02],\n         [ 6.0851e-03],\n         [-1.4299e-01],\n         [ 2.6261e-02],\n         [-8.5588e-02],\n         [-6.9016e-02],\n         [ 6.5341e-02],\n         [ 2.6755e-02],\n         [ 6.7161e-02],\n         [ 3.6479e-02],\n         [ 8.3702e-02],\n         [ 7.8878e-02],\n         [ 2.2633e-03],\n         [-9.3609e-02],\n         [ 3.5879e-02],\n         [ 4.7914e-02],\n         [ 3.4272e-02],\n         [ 9.4067e-02],\n         [ 8.5123e-02],\n         [ 1.0306e-01],\n         [ 5.7576e-02],\n         [-1.6472e-01],\n         [-1.3115e-01],\n         [ 5.3371e-02],\n         [ 7.2237e-02],\n         [ 9.1689e-02],\n         [ 1.0840e-01],\n         [-2.9497e-02],\n         [ 2.6016e-02],\n         [-1.3356e-01],\n         [-5.5971e-02],\n         [ 2.7828e-02],\n         [-1.2602e-01],\n         [-2.7846e-02],\n         [ 1.0337e-02],\n         [ 3.2199e-02],\n         [ 6.5577e-02],\n         [ 7.0873e-03],\n         [ 1.0127e-01],\n         [ 7.4265e-02],\n         [-1.9780e-02],\n         [-1.1951e-01],\n         [ 2.2632e-02],\n         [ 1.2891e-02],\n         [ 4.9793e-02],\n         [ 1.4486e-01],\n         [-2.3406e-02],\n         [-1.0738e-01],\n         [-8.1985e-02],\n         [-1.3365e-01],\n         [-1.1654e-01],\n         [-9.8933e-02],\n         [-1.9452e-01],\n         [ 1.6034e-02],\n         [ 3.6094e-02],\n         [ 5.3258e-02],\n         [-2.3710e-01],\n         [-2.9056e-02],\n         [-3.4522e-02],\n         [-7.5029e-02],\n         [ 1.5167e-02],\n         [-5.7818e-02],\n         [-1.9052e-01],\n         [-4.9695e-02],\n         [-1.9532e-02],\n         [ 1.7130e-02],\n         [ 5.1281e-02],\n         [ 3.4577e-02],\n         [ 5.8452e-02],\n         [ 2.3185e-02],\n         [-4.0352e-02],\n         [-1.1587e-01],\n         [-4.4719e-03],\n         [ 3.4870e-02],\n         [ 9.2072e-02],\n         [ 4.4483e-02],\n         [-1.6308e-01],\n         [-1.8561e-01],\n         [-1.9260e-01],\n         [ 1.2642e-02],\n         [-1.8504e-01],\n         [-1.2096e-01],\n         [-1.4473e-02],\n         [-1.7547e-02],\n         [-3.5331e-02],\n         [-6.3201e-02],\n         [-4.7494e-02],\n         [-8.6618e-02],\n         [-7.9307e-02],\n         [-2.3583e-02],\n         [-5.1021e-02],\n         [-1.4088e-01],\n         [-8.9295e-02],\n         [-2.1472e-02],\n         [-8.5802e-03],\n         [-5.1926e-03]]], grad_fn=<ViewBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"class RegressionDataset(Dataset):\n  \n  def __init__(self, sentences, targets, tokenizer, max_length):\n    self.sentences = sentences\n    self.targets = targets\n    self.tokenizer = tokenizer\n    self.max_length = max_length\n  \n  def __len__(self):\n    return len(self.sentences)\n  \n  def __getitem__(self, idx):\n    sentence = str(self.sentences[idx])\n    target = float(self.targets[idx])\n    encoding = self.tokenizer.encode_plus(\n      sentence,\n      add_special_tokens=True,\n      max_length=self.max_length,\n      return_token_type_ids=False,\n      pad_to_max_length=True,\n      return_attention_mask=True,\n      return_tensors='pt',\n    )\n\n    return {\n        'sentence': sentence,\n        'input_ids': encoding['input_ids'].flatten(),\n        'attention_mask': encoding['attention_mask'].flatten(),\n        'targets': torch.tensor(target, dtype=torch.float)\n    }\n","metadata":{"id":"9NKiDu2dBtRZ","execution":{"iopub.status.busy":"2023-04-23T09:41:45.655155Z","iopub.execute_input":"2023-04-23T09:41:45.655549Z","iopub.status.idle":"2023-04-23T09:41:45.663933Z","shell.execute_reply.started":"2023-04-23T09:41:45.655512Z","shell.execute_reply":"2023-04-23T09:41:45.662656Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def create_data_loaders(sentences, targets, tokenizer, max_input_length, batch_size):\n    ds = RegressionDataset(\n        sentences=sentences,\n        targets=targets,\n        tokenizer=tokenizer,\n        max_length=max_input_length\n    )\n\n    return DataLoader(\n        ds,\n        batch_size=batch_size\n    )","metadata":{"id":"DMU-mmZLCykV","execution":{"iopub.status.busy":"2023-04-23T09:41:45.666501Z","iopub.execute_input":"2023-04-23T09:41:45.667734Z","iopub.status.idle":"2023-04-23T09:41:45.679998Z","shell.execute_reply.started":"2023-04-23T09:41:45.667681Z","shell.execute_reply":"2023-04-23T09:41:45.679030Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_loader = create_data_loaders(\n    train_sentences,\n    train_labels,\n    tokenizer,\n    max_input_length=max_input_length,\n    batch_size=batch_size\n)\n\nval_loader = create_data_loaders(\n    val_sentences,\n    val_labels,\n    tokenizer,\n    max_input_length=max_input_length,\n    batch_size=batch_size\n)\n","metadata":{"id":"5-gNeGVZD0o4","execution":{"iopub.status.busy":"2023-04-23T09:41:45.681440Z","iopub.execute_input":"2023-04-23T09:41:45.682015Z","iopub.status.idle":"2023-04-23T09:41:45.693018Z","shell.execute_reply.started":"2023-04-23T09:41:45.681903Z","shell.execute_reply":"2023-04-23T09:41:45.691879Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class AmazonRegressor(nn.Module):\n\n  def __init__(self, base_model_name):\n    super(AmazonRegressor, self).__init__()\n    self.base_model = AutoModel.from_pretrained(base_model_name)\n    self.drop = nn.Dropout(p=0.3)\n    self.out = nn.Linear(self.base_model.config.hidden_size, 1)\n  \n  def forward(self, input_ids, attention_mask):\n    pooled_output = self.base_model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )['pooler_output']\n    output = self.drop(pooled_output)\n    return self.out(output)\n","metadata":{"id":"5g06Z9zfETFY","execution":{"iopub.status.busy":"2023-04-23T09:41:45.694553Z","iopub.execute_input":"2023-04-23T09:41:45.694951Z","iopub.status.idle":"2023-04-23T09:41:45.704762Z","shell.execute_reply.started":"2023-04-23T09:41:45.694917Z","shell.execute_reply":"2023-04-23T09:41:45.703756Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = AmazonRegressor(base_model_name=model_name)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LTmdztt6FIC1","outputId":"15be62c7-500d-4649-a197-f35e1f254534","execution":{"iopub.status.busy":"2023-04-23T09:41:45.708870Z","iopub.execute_input":"2023-04-23T09:41:45.709210Z","iopub.status.idle":"2023-04-23T09:41:47.426763Z","shell.execute_reply.started":"2023-04-23T09:41:45.709182Z","shell.execute_reply":"2023-04-23T09:41:47.425736Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = AmazonRegressor(base_model_name=model_name)\nmodel.to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"To4zxL48F-98","outputId":"b013f900-a196-41f5-db4d-6e2668d5daa0","execution":{"iopub.status.busy":"2023-04-23T09:41:47.428278Z","iopub.execute_input":"2023-04-23T09:41:47.429337Z","iopub.status.idle":"2023-04-23T09:41:56.674874Z","shell.execute_reply.started":"2023-04-23T09:41:47.429296Z","shell.execute_reply":"2023-04-23T09:41:56.673743Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"AmazonRegressor(\n  (base_model): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (drop): Dropout(p=0.3, inplace=False)\n  (out): Linear(in_features=768, out_features=1, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"num_epochs = 2\n\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n\ntotal_steps = len(train_loader) * num_epochs\n\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\n\nloss_fn = nn.MSELoss().to(device)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OOIp-7GFF-6Z","outputId":"11c17439-62d2-4b91-cef7-eceed4dcd701","execution":{"iopub.status.busy":"2023-04-23T09:41:56.676665Z","iopub.execute_input":"2023-04-23T09:41:56.677119Z","iopub.status.idle":"2023-04-23T09:41:56.691257Z","shell.execute_reply.started":"2023-04-23T09:41:56.677080Z","shell.execute_reply":"2023-04-23T09:41:56.689737Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:395: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_epoch(\n  model, \n  data_loader, \n  loss_fn, \n  optimizer, \n  device, \n  scheduler, \n  n_examples\n):\n  model = model.train()\n\n  losses = []\n  \n  for i, d in enumerate(data_loader):\n    if i % 100 == 0:\n        print(f\"Processing batch {i+1}/{len(data_loader)}\")\n    input_ids = d[\"input_ids\"].to(device)\n    attention_mask = d[\"attention_mask\"].to(device)\n    targets = d[\"targets\"].to(device)\n\n    outputs = model(\n      input_ids=input_ids,\n      attention_mask=attention_mask\n    )\n\n    loss = loss_fn(outputs.squeeze(-1), targets)\n\n    losses.append(loss.item())\n\n    loss.backward()\n    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n    optimizer.step()\n    scheduler.step()\n    optimizer.zero_grad()\n\n  return np.mean(losses)\n","metadata":{"id":"dntx9rurGcmi","execution":{"iopub.status.busy":"2023-04-23T09:41:56.692890Z","iopub.execute_input":"2023-04-23T09:41:56.693444Z","iopub.status.idle":"2023-04-23T09:41:56.702822Z","shell.execute_reply.started":"2023-04-23T09:41:56.693405Z","shell.execute_reply":"2023-04-23T09:41:56.701507Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef eval_model(model, data_loader, loss_fn, device, n_examples):\n  model = model.eval()\n\n  losses = []\n  total_squared_error = 0.0\n\n  with torch.no_grad():\n    for i,d in enumerate(data_loader):\n      if i%100 == 0:\n          print(f\"Processing batch {i+1}/{len(data_loader)}\")\n      input_ids = d[\"input_ids\"].to(device)\n      attention_mask = d[\"attention_mask\"].to(device)\n      targets = d[\"targets\"].to(device)\n\n      print(\"Eval model keys:\", d.keys())  # print out keys of dictionary\n\n      outputs = model(\n        input_ids=input_ids,\n        attention_mask=attention_mask\n      )\n\n      loss = loss_fn(outputs.squeeze(), targets.float().squeeze())\n\n      losses.append(loss.item())\n\n      # calculate squared error\n      squared_error = F.mse_loss(outputs.squeeze(), targets.float(), reduction='none')\n      total_squared_error += squared_error.sum().item()\n\n  mse = total_squared_error / n_examples\n\n  return mse, np.mean(losses)\n\n","metadata":{"id":"uqSE06DGGr1Y","execution":{"iopub.status.busy":"2023-04-23T09:41:56.704223Z","iopub.execute_input":"2023-04-23T09:41:56.704884Z","iopub.status.idle":"2023-04-23T09:41:56.716269Z","shell.execute_reply.started":"2023-04-23T09:41:56.704847Z","shell.execute_reply":"2023-04-23T09:41:56.715252Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tZnoq4xzHiu5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n\n# history = defaultdict(list)\n# best_loss = float('inf')\n\n# for epoch in tqdm(range(num_epochs)):\n\n#   print(f'Epoch {epoch + 1}/{num_epochs}')\n#   print('-' * 10)\n\n#   train_loss = train_epoch(\n#     model,\n#     train_loader,    \n#     loss_fn, \n#     optimizer, \n#     device, \n#     scheduler, \n#     len(train_labels)\n#   )\n\n#   print(f'Train loss {train_loss}')\n\n#   val_loss = eval_model(\n#     model,\n#     val_loader,\n#     loss_fn, \n#     device, \n#     len(val_labels)\n#   )\n\n#   print(f'Val   loss {val_loss}')\n#   print()\n\n#   history['train_loss'].append(train_loss)\n#   history['val_loss'].append(val_loss)\n\n#   if val_loss < best_loss:\n#     torch.save(model.state_dict(), 'best_model_state.bin')\n#     best_loss = val_loss\n","metadata":{"id":"ExUPNmh0Hy-4","execution":{"iopub.status.busy":"2023-04-23T09:41:56.717796Z","iopub.execute_input":"2023-04-23T09:41:56.718523Z","iopub.status.idle":"2023-04-23T09:41:56.730088Z","shell.execute_reply.started":"2023-04-23T09:41:56.718484Z","shell.execute_reply":"2023-04-23T09:41:56.728811Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"%%time\n\nhistory = defaultdict(list)\nbest_loss = float('inf')\n\nfor epoch in tqdm(range(num_epochs)):\n\n  print(f'Epoch {epoch + 1}/{num_epochs}')\n  print('-' * 10)\n\n  train_loss = train_epoch(\n    model,\n    train_loader,    \n    loss_fn, \n    optimizer, \n    device, \n    scheduler, \n    len(train_labels)\n  )\n\n  print(f'Train loss {train_loss}')\n\n  val_loss, val_mse = eval_model(\n    model,\n    val_loader,\n    loss_fn, \n    device, \n    len(val_labels)\n  )\n\n  print(f'Val   loss {val_loss} and Val mse {val_mse}')\n  print()\n\n  history['train_loss'].append(train_loss)\n  history['val_loss'].append(val_loss)\n  history['val_mse'].append(val_mse)\n\n  if val_loss < best_loss:\n    torch.save(model.state_dict(), 'best_model_state.bin')\n    best_loss = val_loss\n    print(\"Saving best model state...\")\n\n  # save the model's state every 5 epochs\n  if (epoch + 1) % 5 == 0:\n    torch.save(model.state_dict(), f'model_state_epoch{epoch+1}.bin')\n    print(f\"Saving model state for epoch {epoch+1}...\")  \n","metadata":{"id":"HBf-c9tZKq1F","colab":{"base_uri":"https://localhost:8080/","height":148},"outputId":"2d98f23e-5596-4ac6-8e90-c3c66f651ee0","execution":{"iopub.status.busy":"2023-04-23T09:41:56.732035Z","iopub.execute_input":"2023-04-23T09:41:56.732476Z","iopub.status.idle":"2023-04-23T10:40:16.663557Z","shell.execute_reply.started":"2023-04-23T09:41:56.732440Z","shell.execute_reply":"2023-04-23T10:40:16.662323Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"  0%|          | 0/2 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 1/2\n----------\nProcessing batch 1/1250\nProcessing batch 101/1250\nProcessing batch 201/1250\nProcessing batch 301/1250\nProcessing batch 401/1250\nProcessing batch 501/1250\nProcessing batch 601/1250\nProcessing batch 701/1250\nProcessing batch 801/1250\nProcessing batch 901/1250\nProcessing batch 1001/1250\nProcessing batch 1101/1250\nProcessing batch 1201/1250\nTrain loss 8400869523.18425\nProcessing batch 1/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 101/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 201/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 301/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nVal   loss 6652745058.3952 and Val mse 6642142113.367413\n\n","output_type":"stream"},{"name":"stderr","text":" 50%|█████     | 1/2 [29:07<29:07, 1747.21s/it]","output_type":"stream"},{"name":"stdout","text":"Saving best model state...\nEpoch 2/2\n----------\nProcessing batch 1/1250\nProcessing batch 101/1250\nProcessing batch 201/1250\nProcessing batch 301/1250\nProcessing batch 401/1250\nProcessing batch 501/1250\nProcessing batch 601/1250\nProcessing batch 701/1250\nProcessing batch 801/1250\nProcessing batch 901/1250\nProcessing batch 1001/1250\nProcessing batch 1101/1250\nProcessing batch 1201/1250\nTrain loss 8400809221.3649\nProcessing batch 1/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 101/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 201/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 301/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nVal   loss 6652721425.144 and Val mse 6642118494.57508\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2/2 [58:19<00:00, 1749.95s/it]","output_type":"stream"},{"name":"stdout","text":"Saving best model state...\nCPU times: user 57min 53s, sys: 11.1 s, total: 58min 4s\nWall time: 58min 19s\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"val_acc, val_loss = eval_model(\nmodel,\nval_loader,\nloss_fn, \ndevice, \nlen(val_labels)\n)\n\nprint(f'Val   loss {val_loss} accuracy {val_acc}')","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:42:16.783246Z","iopub.execute_input":"2023-04-23T10:42:16.783667Z","iopub.status.idle":"2023-04-23T10:44:56.231372Z","shell.execute_reply.started":"2023-04-23T10:42:16.783631Z","shell.execute_reply":"2023-04-23T10:44:56.230019Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Processing batch 1/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 101/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 201/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nProcessing batch 301/313\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nEval model keys: dict_keys(['sentence', 'input_ids', 'attention_mask', 'targets'])\nVal   loss 6642118494.57508 accuracy 6652721425.144\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.plot(history['train_acc'], label='train accuracy')\nplt.plot(history['val_acc'], label='validation accuracy')\n\nplt.title('Training history')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend()\nplt.ylim([0, 1]);","metadata":{"execution":{"iopub.status.busy":"2023-04-23T10:47:23.275654Z","iopub.execute_input":"2023-04-23T10:47:23.276251Z","iopub.status.idle":"2023-04-23T10:47:23.647259Z","shell.execute_reply.started":"2023-04-23T10:47:23.276209Z","shell.execute_reply":"2023-04-23T10:47:23.646227Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}